# CH 01 The Machine Learning Landscape

## Batch and Online Leaning

### Batch learning

In batch learning, the system is incapable of learning incrementally: it must be trained using all the available data. This will generally take a lot of time and computing resources, so it is typically done offline. 

- First the system is trained, and then it is launched into production and runs without learning anymore;
  - It just applies what it has learned. This is called ***offline learning.***

### Online learning

In online learning, you train the system incrementally ***by feeding it data instances sequentially,*** either individually or in small groups called ***mini-batches.***

- Online learning is great for systems that receive data as a continuous flow (e.g., stock prices) and need to adapt to change rapidly or autonomously.
- It is also a good option if you have limited computing resources: once an online learning system has learned
  about new data instances, it does not need them anymore, so you can discard them ***(unless you want to be able to roll back to a previous state and “replay” the data).***
- ***Online learning algorithms can also be used to train systems on huge datasets that cannot fit in one machine’s main memory (this is called out-of-core learning).***

One important parameter of online learning systems is how fast they should adapt to changing data: this is called the ***learning rate.***

- If you set a ***high learning rate***, then your system will rapidly adapt to new data, but it will also tend to quickly forget the old data.
  - 러닝 레이트가 높으면 새로운 데이터 학습 잘하지만 기존 데이터 금방 잊음
- Conversely, if you set a ***low learning rate***, the system will have more inertia; that is, it will learn more slowly, but it will also be less sensitive to noise in the new data or to sequences of non-representative data points (outliers).
  - 러닝 레이트 낮으면 새로운 데이터 들어와도 기존 데이터의 경향을 따라가려함 (관성)

## Instance-Based Versus Model-Based Learning

### Instance-based learning

This requires a measure of similarity between two emails. A (very basic) similarity measure between two emails could be to count the number of words they have in common. The system would flag an email as spam if it has many words in common with a known spam email.

- This is called ***instance-based learning***: the system learns the examples by heart, then generalizes to new cases by using a similarity measure to compare them to the learned examples (or a subset of them). 

### Model-based learning

Another way to generalize from a set of examples is to ***build a model of these examples and then use that model to make predictions.***

- This is called model-based learning

## Test and Validating

The error rate on new cases is called the ***generalization error*** (or out-of-sample error)

### Hyperparameter Tuning and Model Selection

The problem is that you measured the generalization error multiple times on the test set, and you adapted the model and hyperparameters to produce the best model for that particular set.

- This means that the model is unlikely to perform as well on new data.
  - Test set에 한해서만 정상적으로 동작하는 경우가 있음
- A common solution to this problem is called ***holdout validation***: you simply hold out part of the training set to evaluate several candidate models and select the best one.
  - ***The new held-out set is called the validation set***(or sometimes the development set, or dev set)
- More specifically, you train multiple models with various hyperparameters on the reduced training set (i.e., the full training set minus the validation set), and you select the model that performs best on the validation set.
- After this holdout validation process, you train the best model on the full training set (including the validation set), and this gives you the final model. Lastly, you evaluate this final model on the test set to get an estimate of the generalization error.
  - 비교할 모델들을 트레이닝 셋(Training set)에서 검증 셋 을뺸 데이터 셋트 트레이닝 시킴
  - 훈련 시킬 모델들을 검증 셋을 이용해서 비교하고 더 좋은 모델을 선택함
  - 선택한 모델을 검증 셋이 포함된 트레이닝 셋으로 훈련시킴
- ***cross-validation*** :  using many small validation sets.
  - Each model is evaluated once per validation set after it is trained on the rest of the data.

## Exercise

How would define Machine Learning?

- The way to find a solution using data.
- It tries to find a tendency or patterns

What are the two most common supervised tasks?

- Regression
- Classification

Can you name four common unsupervised tasks?

- Clustering
- Visualization
- Dimensionality reduction
- Association rule learning

What type of algorithm would you use to segment your customers into multiple groups?

- Have sample : Supervised learning
- No sample : Unsupervised learning

What is an online learning system?

- Learn using instance data
- Opposition of batch learning
- Good for very quantities of data

What type of learning algorithm relies on a similarity measure to make predictions?

- Instance-based learning system

What is the difference between a model parameter and a learning algorithm’s hyperparameter?

- Hyperparameter : User tune
- Model parameter : It is tuned by model

Can you name four of the main challenges in Machine Learning?

- Lack of data
- Poor data quality
- Nonrepresentative data
- Uninformative features

If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?

- It means that model only works for test data set. So It needs to make a validation set which are part of training set.

What is the train-dev set, when do you need it, and how do you use it?

- Train-dev set us used ***when there is a risk of mismatch between the training data test datasets***
- The train-dev set is a part of the training set that is held out.
  - Train-dev : To find data mismatch
  - Validation set : To find mismatch between training set and test set